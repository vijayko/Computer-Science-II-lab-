{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 2: Training Your First TF Linear Regression Model",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JndnmDMp66FL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijayko/Computer-Science-II-lab-/blob/master/Lab_2_Training_Your_First_TF_Linear_Regression_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JndnmDMp66FL"
      },
      "source": [
        "#### Copyright 2018 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "hMqWDc_m6rUC",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lab_objectives"
      },
      "source": [
        "# Lab 2: Training Your First TF Linear Regression Model\n",
        "** Learning Objectives **\n",
        "* Use pyplot to help visualize the data, the learned model, and how the loss is evolving during training.\n",
        "* Learn how to set up the features in TensorFlow to train a model.\n",
        "* Use the LinearRegressor class in TensorFlow to predict a real-valued featured based on one real-valued input feature.\n",
        "* Evaluate the accuracy of a model's predictions using Root Mean Squared Error (RMSE) and understand the learning curve.\n",
        "* Improve the accuracy of a model by tuning the learning rate and number of training steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "combined_import_panda_text"
      },
      "source": [
        "### Imports and Pandas Options\n",
        "We import the libraries we are using and set some panda options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "combined_import_panda_code",
        "colab": {}
      },
      "source": [
        "import fnmatch\n",
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "# This line increasing the amount of logging when there is an error.  You can\n",
        "# remove it if you want less logging\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# Set the output display to have two digits for decimal places, for display\n",
        "# readability only and limit it to printing 15 rows.\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "pd.options.display.max_rows = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "data_set_text_short_description"
      },
      "source": [
        "### Data Set\n",
        "As in the last lab we use the [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/automobile)  from 1985 Ward's Automotive Yearbook that is part of the  [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "load_auto_data_set_text"
      },
      "source": [
        "### Loading and Randomizing the Data\n",
        "Load the data using the column names from [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/automobile). When using SGD (stochastic graident descent) for training it is important that **each batch is a random sample of the data** so that the gradient computed is representative.  While there appears to be no order to this data set, it is always good practice to shuffle the data to be in a random order.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "load_auto_data_set_code",
        "colab": {}
      },
      "source": [
        "# Provide the names for the columns since the CSV file with the data does\n",
        "# not have a header row.\n",
        "cols = ['symboling', 'losses', 'make', 'fuel-type', 'aspiration', 'num-doors',\n",
        "        'body-style', 'drive-wheels', 'engine-location', 'wheel-base',\n",
        "        'length', 'width', 'height', 'weight', 'engine-type', 'num-cylinders',\n",
        "        'engine-size', 'fuel-system', 'bore', 'stroke', 'compression-ratio',\n",
        "        'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
        "\n",
        "\n",
        "# Load in the data from a CSV file that is comma seperated.\n",
        "car_data = pd.read_csv('https://storage.googleapis.com/ml_universities/cars_dataset/cars_data.csv',\n",
        "                        sep=',', names=cols, header=None, encoding='latin-1')\n",
        "\n",
        "# We'll then randomize the data, just to be sure not to get any pathological\n",
        "# ordering effects that might harm the performance of Stochastic Gradient\n",
        "# Descent.\n",
        "car_data = car_data.reindex(np.random.permutation(car_data.index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "line_in_scatter_plot_text"
      },
      "source": [
        "###Visualizing a Linear Model Using a Scatter Plot\n",
        "\n",
        "When training a linear regression model over a single variable, a really nice thing to be able to do is to show the model (which is just a line) as part of the scatter plot. That really helps you see how well the model fits the data. Just looking at the loss (RMSE here) doesn't really indicate how good the model is. Sometimes you want to show several models on the same scatter plot to compare them so we allow slopes, biases, and model_names to all be lists. They should be of the same size giving the weight (slope), bias, and name (to use in the legend) for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "scatter_plot_function",
        "colab": {}
      },
      "source": [
        "def scatter_plot(features, targets, slopes=[], biases=[], model_names=[]):\n",
        "  \"\"\" Creates a scatter plot of input_feature vs target along with the models.\n",
        "  \n",
        "  Args:\n",
        "    features: list of the input features\n",
        "    targets: list of targets\n",
        "    slopes: list of model weight (slope) \n",
        "    bias: list of model bias (same size as slopes)\n",
        "    model_names: list of model_names to use for legend (same size as slopes)\n",
        "  \"\"\"      \n",
        "  # Define some colors to use that go from blue towards red\n",
        "  colors = [cm.coolwarm(x) for x in np.linspace(0, 1, len(slopes))]\n",
        "  \n",
        "  # Generate the Scatter plot\n",
        "  plt.ylabel(\"target\")\n",
        "  plt.xlabel(\"input feature\")\n",
        "  plt.scatter(features, targets, color='black', label=\"\")\n",
        "  \n",
        "  # Add the lines corresponding to the provided models\n",
        "  for i in range (0, len(slopes)):\n",
        "    y_0 = slopes[i] * features.min() + biases[i]\n",
        "    y_1 = slopes[i] * features.max() + biases[i]\n",
        "    plt.plot([features.min(), features.max()], [y_0, y_1],\n",
        "             label=model_names[i], color=colors[i])\n",
        "  if (len(model_names) > 0):\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "convert_missing_to_mean_text"
      },
      "source": [
        "### Converting Missing Numerical Values to the Column Mean\n",
        "\n",
        "As you hopefully found in a previous exercise, a good option for replacing missing entries (NaN) is to replace them by the column mean.  We do that here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "convert_missing_to_mean_code",
        "colab": {}
      },
      "source": [
        "car_data['price'] = pd.to_numeric(car_data['price'], errors='coerce')\n",
        "car_data['horsepower'] = pd.to_numeric(car_data['horsepower'], errors='coerce')\n",
        "car_data['peak-rpm'] = pd.to_numeric(car_data['peak-rpm'], errors='coerce')\n",
        "car_data['city-mpg'] = pd.to_numeric(car_data['city-mpg'], errors='coerce')\n",
        "car_data['highway-mpg'] = pd.to_numeric(car_data['highway-mpg'], errors='coerce')\n",
        "\n",
        "# Replace nan by the mean storing the solution in the same table (`inplace')\n",
        "car_data.fillna(car_data.mean(), inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "build_first_tf_model_text"
      },
      "source": [
        "### Build Your First Tensor Flow Model\n",
        "\n",
        "We now build a model to predict `price`, which will be our label (sometimes also called a target) using `horsepower` as our input feature. To train our model, we'll use the [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) interface provided by the TensorFlow [Estimator](https://www.tensorflow.org/get_started/estimator) API. This API takes care of a lot of the low-level model plumbing, and exposes convenient methods for performing model training, evaluation, and inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "prepare_features_text"
      },
      "source": [
        "###Prepare Features\n",
        "As our learning models get more sophisticated we will want to do some computation on the features and even generate new features from the existing ones. We will see examples of this in later labs.  For now this method will just make a copy of a portion of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "prepare_features_code",
        "colab": {}
      },
      "source": [
        "def prepare_features(dataframe):\n",
        "  \"\"\"Prepares the features for provided dataset.\n",
        "\n",
        "  Args:\n",
        "    dataframe: A Pandas DataFrame expected to contain data from the\n",
        "      desired data set.\n",
        "  Returns:\n",
        "    A new dataFrame that contains the features to be used for the model.\n",
        "  \"\"\"\n",
        "  processed_features = dataframe.copy()\n",
        "  return processed_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "generate_training_examples_text"
      },
      "source": [
        "###Generate the Training Examples\n",
        "We simply call `prepare_features` on the `car_data` dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "generate_training_examples_code",
        "colab": {}
      },
      "source": [
        "training_examples = prepare_features(car_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "setting_up_numerical_feature_columns_text"
      },
      "source": [
        "###Setting Up the Feature Columns for TensorFlow\n",
        "\n",
        "In order to import our training data into TensorFlow, we need to specify what type of data each feature contains. There are two main types of data we'll use in this and future exercises:\n",
        "\n",
        "* **Numerical Data**: Data that is a number (integer or float) and that you want to treat as a number. As we will discuss more later, sometimes you might want to treat numerical data (e.g., a postal code) as if it were categorical.\n",
        "\n",
        "* **Categorical Data**: Data that is textual such as `make` or `fuel-type`.\n",
        "\n",
        "In TensorFlow, we indicate a feature's data type using a construct called a **feature column**. Feature columns store only a description of the feature data; they do not contain the feature data itself.\n",
        "\n",
        "For now, we will just use numerical features.  Later you will learn how to use categorical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "setting_up_numerical_feature_columns_code",
        "colab": {}
      },
      "source": [
        "NUMERICAL_FEATURES = [\"horsepower\"]\n",
        "\n",
        "def construct_feature_columns():\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\" \n",
        "  return set([tf.feature_column.numeric_column(feature)\n",
        "              for feature in NUMERICAL_FEATURES])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "input_function_text"
      },
      "source": [
        "### Input Function\n",
        "To import our data into a LinearRegressor, we need to define an input function, which instructs TensorFlow how to preprocess the data, as well as how to batch, shuffle, and repeat it during model training.\n",
        "\n",
        "First, we'll convert our Pandas feature data into a dictionary of NumPy arrays. We can then use the TensorFlow Dataset API to construct a dataset object from our data, and then break our data into batches of batch_size, to be repeated for the specified number of epochs (num_epochs).\n",
        "\n",
        "When the default value of num_epochs=None is passed to [Dataset.repeat()](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#repeat), the input data will be repeated indefinitely.\n",
        "\n",
        "Next, if shuffle is set to True, we'll shuffle the data so that it's passed to the model randomly during training. We'll shuffle the data using [Dataset.shuffle()](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle), which receives a parameter buffer_size that specifies the size of the dataset from which shuffle will randomly sample.\n",
        "\n",
        "Finally, our input function constructs an iterator for the dataset and returns the next batch of data to the LinearRegressor.\n",
        "\n",
        "**NOTE:** We'll continue to use this same input function in later exercises. For more\n",
        "detailed documentation of input functions and the `Dataset` API, see the [TensorFlow Programmer's Guide](https://www.tensorflow.org/programmers_guide/datasets)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "input_function_code",
        "colab": {}
      },
      "source": [
        "def input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
        "    \"\"\"Defines a function to preprocess the data, as well as how to batch,\n",
        "      shuffle, and repeat it during model training..\n",
        "  \n",
        "    Args:\n",
        "      features: pandas DataFrame of features\n",
        "      targets: pandas DataFrame of targets\n",
        "      batch_size: Size of batches to be passed to the model\n",
        "      shuffle: True or False. Whether to shuffle the data.\n",
        "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
        "    Returns:\n",
        "      Tuple of (features, labels) for next data batch\n",
        "    \"\"\"\n",
        "    \n",
        "    # Convert pandas data into a dict of np arrays.\n",
        "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
        " \n",
        "    # Construct a dataset, and configure batching/repeating.\n",
        "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
        "    ds = ds.repeat(num_epochs)\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(10000)\n",
        "    ds = ds.batch(batch_size)\n",
        "    \n",
        "    # Return the next batch of data.\n",
        "    features, labels = ds.make_one_shot_iterator().get_next()\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "configure_linear_regressor_text"
      },
      "source": [
        "###Configure the LinearRegressor\n",
        "\n",
        "Next, we'll configure a linear regression model using LinearRegressor. We'll train this model using the `GradientDescentOptimizer`, which implements Mini-Batch Stochastic Gradient Descent (SGD). The `learning_rate` argument controls the size of the gradient step.\n",
        "\n",
        "**NOTE:** To be safe, we also apply [gradient clipping](https://developers.google.com/machine-learning/glossary/#gradient_clipping) to our optimizer via `clip_gradients_by_norm`. Gradient clipping ensures the magnitude of the gradients do not become too large during training, which can cause gradient descent to fail. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "configure_linear_regressor_code",
        "colab": {}
      },
      "source": [
        "def define_linear_regression_model(learning_rate):\n",
        "  \"\"\" Defines a linear regression model of one feature to predict the target.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate\n",
        "    \n",
        "  Returns:\n",
        "    A linear regressor created with the given learning rate\n",
        "  \"\"\"\n",
        "  \n",
        "  optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, 5.0)\n",
        "  linear_regressor = tf.estimator.LinearRegressor(\n",
        "    feature_columns=construct_feature_columns(),\n",
        "    optimizer=optimizer\n",
        "  )  \n",
        "  return linear_regressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "train_model_text"
      },
      "source": [
        "###Train the Model\n",
        "\n",
        "We now have all the pieces we need to train a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "train_model_code",
        "colab": {}
      },
      "source": [
        "NUMERICAL_FEATURES = [\"horsepower\"]\n",
        "CATEGORICAL_FEATURES = []\n",
        "LABEL = \"price\"\n",
        "\n",
        "# Create regression model using the define_regression_model procedure that we\n",
        "# defined earlier.\n",
        "linear_regressor = define_linear_regression_model(learning_rate = 1)\n",
        "\n",
        "train_input_fn = lambda: input_fn(training_examples[NUMERICAL_FEATURES], \n",
        "                                  training_examples[LABEL], \n",
        "                                  batch_size=50)\n",
        "\n",
        "# Train the predictor using 100 steps through the data.\n",
        "_ = linear_regressor.train(\n",
        "      input_fn=train_input_fn, steps=100\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "evaluate_model_text"
      },
      "source": [
        "### Evaluate the Model\n",
        "\n",
        "Let's make predictions on that training data, to see how well our model fit it during training.\n",
        "\n",
        "**NOTE:** Training error measures how well your model fits the training data, but it **_does not_** measure how well your model **_generalizes to new data_**. In later exercises, you'll explore how to split your data to evaluate your model's ability to generalize.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "evaluate_model_code",
        "colab": {}
      },
      "source": [
        "features = training_examples[NUMERICAL_FEATURES]\n",
        "targets = training_examples[LABEL]\n",
        "training_predict_input_fn = lambda: input_fn(\n",
        "    features, targets, num_epochs=1, shuffle=False)\n",
        "\n",
        "# Call predict() on the linear_regressor to make predictions.\n",
        "predictions = linear_regressor.predict(input_fn=training_predict_input_fn)\n",
        "\n",
        "# Format predictions as a NumPy array, so we can calculate error metrics.\n",
        "predictions = np.array([item['predictions'][0] for item in predictions])\n",
        "\n",
        "# Print Mean Squared Error and Root Mean Squared Error.\n",
        "mean_squared_error = metrics.mean_squared_error(predictions, targets)\n",
        "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
        "print(\"Mean Squared Error (on training data): %0.3f\" % mean_squared_error)\n",
        "print(\"Root Mean Squared Error (on training data): %0.3f\" % root_mean_squared_error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "get_weights_text"
      },
      "source": [
        "### Looking at the Feature Weight (Slope) and Bias of Our Trained Model\n",
        "\n",
        "TensorFlow provides an easy way to view the weights of the trained model. Although we just have a single feature right now, this code block shows how you could access and print all of the feature weights for a linear model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "get_weights_code",
        "colab": {}
      },
      "source": [
        "w = linear_regressor.get_variable_value('linear/linear_model/horsepower/weights')[0]\n",
        "b = linear_regressor.get_variable_value('linear/linear_model/bias_weights')[0]\n",
        "scatter_plot(features.values, targets,[w], [b], ['trained model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "compute_loss_text"
      },
      "source": [
        "### Computing the Loss\n",
        "For now we are using root mean squared error (RMSE) for our loss since that is the appropriate loss to use for linear regression.  However, to keep the procedure to train the model very generic, we introduce a method to compute loss that can be tailored to other types of problems. For this lab, our implementation will be to return the RMSE.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "compute_loss_code",
        "colab": {}
      },
      "source": [
        "def compute_loss(predictions, targets):\n",
        "  \"\"\" Computes the loss (RMSE) for linear regression.\n",
        "  \n",
        "  Args:\n",
        "    predictions: a list of values predicted by the model being visualized\n",
        "    targets: a list of the target values being predicted that must be the\n",
        "             same size as predictions.\n",
        "    \n",
        "  Returns:\n",
        "    The RMSE for the provided predictions and targets\n",
        "  \"\"\"      \n",
        "  return math.sqrt(metrics.mean_squared_error(predictions, targets))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "learning_curve_text"
      },
      "source": [
        "###Learning Curve\n",
        "\n",
        "Another important tool is a graph often called a **learning curve** that shows the loss being minimized on the y-axis and the training steps (time) on the x-axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "learning_curve_code",
        "colab": {}
      },
      "source": [
        "def plot_learning_curve(training_losses):\n",
        "  \"\"\" Plot the learning curve\n",
        "  \n",
        "  Args:\n",
        "    training_loses: a list of losses to plot\n",
        "  \"\"\"        \n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Training Steps')\n",
        "  plt.plot(training_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "train_model_scatter_plot_text"
      },
      "source": [
        "###Training Our Model with a Learning Curve and Scatter Plot\n",
        "\n",
        "We now have all the pieces we need to train a model in a way that we can tune the learning rate and  visually evaluate how the model is performing.  In order to generate intermediate losses for the learning curve (and record as we are training), we divide the training into 10 periods.  After each period we compute the loss.  We also store the weight and bias of the model at that time so that we can then visually show how the model evolves in a scatter plot.  You are welcome to modify the number of periods but 10 seems to work out pretty well. \n",
        "\n",
        "We start by using a *scatter plot* as our visualization for understanding how the model evolves when training but this can only easily be done with a single numerical feature.  Later we will switch to a different visualization that can be used for any linear model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "train_model_scatter_plot_code",
        "colab": {}
      },
      "source": [
        "# Function to train the model when there is a single numeric feature, which\n",
        "# allows using the scatter plot as a visualization with the progession of the\n",
        "# model.\n",
        "def train_model_with_one_numerical_feature(linear_regressor, features, labels,\n",
        "                                           steps, batch_size):\n",
        "  \"\"\"Trains a linear regression model.\n",
        "  \n",
        "  Args:\n",
        "    linear_regressor: The regressor to train\n",
        "    features: The list of input feature values\n",
        "    labels: The label values\n",
        "    steps: A non-zero `int`, the total number of training steps.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    \n",
        "  Returns:\n",
        "    The trained regressor\n",
        "  \"\"\"\n",
        "  # In order to see how the model evolves as we train it, we will divide the\n",
        "  # steps into periods and show the model after each period.\n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "  \n",
        "  # Set up the training_input_fn and predict_training_input_fn\n",
        "  training_input_fn = lambda: input_fn(features, labels, batch_size=batch_size)\n",
        "  predict_training_input_fn = lambda: input_fn(features, labels, num_epochs=1,\n",
        "                                               shuffle=False)\n",
        "  \n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.  We store the loss, slope (feature weight), bias, and a name\n",
        "  # for the model when there is a single feature (which would then allows us\n",
        "  # to plot the model in a scatter plot).\n",
        "  print(\"Training model...\")\n",
        "  training_losses = []\n",
        "  slopes = []\n",
        "  biases = []\n",
        "  model_names = []\n",
        "\n",
        "  for period in range (0, periods):\n",
        "    # Call fit to train the regressor for steps_per_period steps\n",
        "    _ = linear_regressor.train(input_fn=training_input_fn, steps=steps_per_period)\n",
        "\n",
        "    # Use the predict method to compute the predictions from the current model\n",
        "    predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\n",
        "    predictions = np.array([item['predictions'][0] for item in predictions])\n",
        "   \n",
        "    # Compute the loss between the predictions and the correct labels, append\n",
        "    # the loss to the list of losses used to generate the learning curve after\n",
        "    # training is complete and print the current loss\n",
        "    loss = compute_loss(predictions, labels)\n",
        "    training_losses.append(loss) \n",
        "    print(\"  Loss after period %02d : %0.3f\" % (period, loss))\n",
        "    \n",
        "    # Add slope, bias and model_name to the lists to be used later to plot\n",
        "    # the model after each training period.\n",
        "    feature_weight = fnmatch.filter(linear_regressor.get_variable_names(),\n",
        "                                    'linear/linear_model/*/weights')\n",
        "    slopes.append(linear_regressor.get_variable_value(feature_weight[0])[0])\n",
        "    biases.append(linear_regressor.get_variable_value(\n",
        "        'linear/linear_model/bias_weights')[0])\n",
        "    model_names.append(\"period_\" + str(period))\n",
        "      \n",
        "  # Now that training is done print the final loss    \n",
        "  print(\"Final Loss (RMSE) on the training data: %0.3f\" % loss) \n",
        "  \n",
        "  # Generate a figure with the learning curve on the left and a scatter plot\n",
        "  # on the right\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.title(\"Learning Curve (RMSE vs time)\")\n",
        "  plot_learning_curve(training_losses)\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.tight_layout(pad=1.1, w_pad=3.0, h_pad=3.0)\n",
        " \n",
        "  plt.title(\"Learned Model by Period on Scatter Plot\")\n",
        "  scatter_plot(features.values, labels, slopes, biases, model_names)   \n",
        "  return linear_regressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "learning_rate_high_text"
      },
      "source": [
        "### Example Learning Curve When the Learning Rate is Too High\n",
        "\n",
        "When the learning rate is too high you will see the loss going up and down indicating you are making adjustments that are too large.  When you see this happening lower the learning rate (initially by a factor of 10 and then make smaller adjustments when you are close).  In this case you are moving back and forth between having the slope too large and too small."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "learning_rate_high_code",
        "colab": {}
      },
      "source": [
        "NUMERICAL_FEATURES = [\"horsepower\"]\n",
        "CATEGORICAL_FEATURES = []\n",
        "LABEL = \"price\"\n",
        "\n",
        "LEARNING_RATE = 100\n",
        "STEPS = 50\n",
        "\n",
        "linear_regressor = define_linear_regression_model(learning_rate = LEARNING_RATE)\n",
        "linear_regressor = train_model_with_one_numerical_feature(\n",
        "    linear_regressor, training_examples[NUMERICAL_FEATURES],\n",
        "    training_examples[LABEL], batch_size=50, steps=STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "learning_rate_low_text"
      },
      "source": [
        "### Example Learning Curve When the Learning Rate is Too Low\n",
        "\n",
        "When the learning rate is too low then the changes are too small.  While this might eventually get you to a good solution it would take way more steps than needed and the training time is roughly proportinal to the number of steps so you want to find a learning rate that gets you to a good solution as fast as you can.  You can see for these settings that the model learned (the line you see in the scatter plot) is improving and would eventually get there but is taking much, much longer than needed to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "learning_rate_low_code",
        "colab": {}
      },
      "source": [
        "NUMERICAL_FEATURES = [\"horsepower\"]\n",
        "CATEGORICAL_FEATURES = []\n",
        "LABEL = \"price\"\n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "STEPS = 10000\n",
        "\n",
        "linear_regressor = define_linear_regression_model(learning_rate = LEARNING_RATE)\n",
        "linear_regressor = train_model_with_one_numerical_feature(\n",
        "    linear_regressor, training_examples[NUMERICAL_FEATURES],\n",
        "    training_examples[LABEL], batch_size=50, steps=STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise_modify_hyperparams_text"
      },
      "source": [
        "##Exercise: Modify the Hyperparmaters to Get a Better Model (1 Point)\n",
        "For this task, you can use the code block below that puts all the above code in a single cell for convenience. Focus on first finding a good learning rate and then adjusting the number of steps to be what you need to converge.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "exercise_modify_hyperparams_code",
        "colab": {}
      },
      "source": [
        "NUMERICAL_FEATURES = [\"horsepower\"]\n",
        "CATEGORICAL_FEATURES = []\n",
        "LABEL = \"price\"\n",
        "\n",
        "## Fill in the rest of your solution here.  Feel free to introduce multiple\n",
        "## code boxes if you want to see the solutions and learning curves from\n",
        "## different options at the same time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exercise_additional_questions",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "List at least 3 of the sets of hyperparameters you tried and the RMSE obtained.\n",
        "Your primary goal is to get the lowest RMSE you can.  Once you've done that a\n",
        "secondary goal is to minmize the number of steps used since the computation\n",
        "cost depends heavily on the number of steps.\n",
        "\n",
        "Please Submit this with the results from the hyperparameters that you feel\n",
        "worked best.\n",
        "\n",
        "TYPE YOUR ANSWER IN THIS COMMENT\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise_try_different_feature_text"
      },
      "source": [
        "##Exercise: Try a Different Input Feature (4 Points)\n",
        "\n",
        "The choice of the hyperparameters depends a lot on the data set and what you are trying to learn.  In this task you will try to predict the price from highway mpg and find a good set of hyperparameters for this problem.\n",
        "\n",
        "* Use highway-mpg instead of horsepower to predict price. You might want to start by just plotting the data.  What do you observe?\n",
        "* What hyperparameters give you the best trained model that you can get.  Try to keep the learning steps as small as you can while still training a good model.\n",
        "* Did you have to change the hyperparameters a lot?  If you did, why do you think that might be the case?\n",
        "* How does the RMSE for your model compare to the optimal RMSE?  Think about what you'll need to do in order to answer this question."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exercise_try_different_feature_code",
        "colab": {}
      },
      "source": [
        "NUMERICAL_FEATURES = [\"highway-mpg\"]\n",
        "CATEGORICAL_FEATURES = []\n",
        "LABEL = \"price\"\n",
        "\n",
        "## Fill in the rest of your solution here."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exercise_additional_questions_2",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "TYPE YOUR ANSWERS TO THE GIVEN QUESTIONS HERE\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}